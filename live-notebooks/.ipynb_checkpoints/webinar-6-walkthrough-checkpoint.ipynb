{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. A complete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import colorama\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LeNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture Details**\n",
    "\n",
    "+ Convolutional part:\n",
    "\n",
    "\n",
    "| Layer       | Name | Input channels | Output channels | Kernel | stride |\n",
    "| ----------- | :--: | :------------: | :-------------: | :----: | :----: |\n",
    "| Convolution |  C1  |       1        |        6        |  5x5   |   1    |\n",
    "| ReLU        |      |       6        |        6        |        |        |\n",
    "| MaxPooling  |  S2  |       6        |        6        |  2x2   |   2    |\n",
    "| Convolution |  C3  |       6        |       16        |  5x5   |   1    |\n",
    "| ReLU        |      |       16       |       16        |        |        |\n",
    "| MaxPooling  |  S4  |       16       |       16        |  2x2   |   2    |\n",
    "| Convolution |  C5  |       6        |       120       |  5x5   |   1    |\n",
    "| ReLU        |      |      120       |       120       |        |        |\n",
    "\n",
    "\n",
    "+ Fully Connected part:\n",
    "\n",
    "| Layer      | Name | Input size | Output size |\n",
    "| ---------- | :--: | :--------: | :---------: |\n",
    "| Linear     |  F5  |    120     |     84      |\n",
    "| ReLU       |      |            |             |\n",
    "| Linear     |  F6  |     84     |     10      |\n",
    "| LogSoftmax |      |            |             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            nn.Conv2d(6, 16, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 120, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        output = self.conv_net(imgs)\n",
    "        output = output.view(imgs.shape[0], -1)  # imgs.shape[0] is the batch_size\n",
    "        output = self.fully_connected(output)\n",
    "        return output        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net = LeNet5()\n",
    "print(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_params = list(conv_net.named_parameters())\n",
    "print(\"len(params): %s\\n\" % len(named_params))\n",
    "for name, param in named_params:\n",
    "    print(\"%s:\\t%s\" % (name, param.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed network with a random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 32, 32)  # batch_size, num_channels, height, width\n",
    "out = conv_net(input)\n",
    "\n",
    "print(\"Log-Probabilities: \\n%s\\n\" % out)\n",
    "print(\"out.shape: \\n%s\" % (out.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Loading the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('../', \n",
    "                            train = True, \n",
    "                            download = True,\n",
    "                            transform = transformations)\n",
    "\n",
    "test_data = datasets.MNIST('../', \n",
    "                            train = False, \n",
    "                            download = True,\n",
    "                            transform = transformations)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, device, num_epochs=3, lr=0.1):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"=\" * 20, \"Starting epoch %d\" % (epoch + 1), \"=\" * 20)\n",
    "        \n",
    "        model.train()  # Not necessary in our example, but still good practice.\n",
    "                       # Only models with nn.Dropout and nn.BatchNorm modules require it\n",
    "                \n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if batch_idx % 40 == 0:\n",
    "                print(\"Batch %d/%d, Loss=%.4f\" % (batch_idx, len(train_loader), loss.item()))\n",
    "        \n",
    "        train_acc = accuracy(model, train_loader, device)\n",
    "        test_acc = accuracy(model, test_loader, device)\n",
    "        \n",
    "        print(\"\\nAccuracy on training: %.2f%%\" % (100*train_acc))\n",
    "        print(\"Accuracy on test: %.2f%%\" % (100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataloader, device):\n",
    "    \"\"\" Computes the model's accuracy on the data provided by 'dataloader'\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    with torch.no_grad():  # deactivates autograd, reduces memory usage and speeds up computations\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(data).argmax(1)\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "conv_net = conv_net.to(device)\n",
    "\n",
    "train(conv_net, train_loader, test_loader, device, lr=2e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
